{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questionnaire Loader Debug Notebook\n",
    "\n",
    "This notebook allows manual inspection and debugging of the QuestionnaireLoader.\n",
    "\n",
    "## What it loads:\n",
    "- Demographics: Age, Gender, Height, Weight, etc.\n",
    "- Mental Health: OASIS, PCL-5, PHQ9, GAD7, Depression, Anxiety\n",
    "- Personality: Big 5 traits (Extraversion, Agreeableness, etc.)\n",
    "- Lifestyle: Exercise, Caffeine, Sleep (PSQI), Screen time\n",
    "- Socioeconomic: Education, Work status, Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Set up paths - questionnaire data is typically a standalone CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the questionnaire CSV path\n",
    "# This is typically the IntegratedQ export file\n",
    "QUESTIONNAIRE_CSV = os.getenv(\"QUESTIONNAIRE_CSV\", None)\n",
    "SESSIONS_CSV = os.getenv(\"SESSIONS_CSV\", None)\n",
    "\n",
    "# Optionally override paths here:\n",
    "# QUESTIONNAIRE_CSV = \"/path/to/Qcenter_-_IntegratedQ.csv\"\n",
    "# SESSIONS_CSV = \"/path/to/sessions.csv\"\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  QUESTIONNAIRE_CSV: {QUESTIONNAIRE_CSV}\")\n",
    "print(f\"  SESSIONS_CSV: {SESSIONS_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify Paths Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_path(path, name):\n",
    "    if path is None:\n",
    "        print(f\"  {name}: NOT SET\")\n",
    "        return False\n",
    "    p = Path(path)\n",
    "    exists = p.exists()\n",
    "    print(f\"  {name}: {'EXISTS' if exists else 'MISSING'} - {p}\")\n",
    "    return exists\n",
    "\n",
    "print(\"Path verification:\")\n",
    "questionnaire_exists = check_path(QUESTIONNAIRE_CSV, \"QUESTIONNAIRE_CSV\")\n",
    "sessions_exists = check_path(SESSIONS_CSV, \"SESSIONS_CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect Raw CSV Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw CSV to inspect structure\n",
    "if QUESTIONNAIRE_CSV and Path(QUESTIONNAIRE_CSV).exists():\n",
    "    raw_df = pd.read_csv(QUESTIONNAIRE_CSV)\n",
    "    print(f\"Raw questionnaire CSV loaded: {len(raw_df)} rows, {len(raw_df.columns)} columns\")\n",
    "    print(f\"\\nColumn names ({len(raw_df.columns)} total):\")\n",
    "    for i, col in enumerate(raw_df.columns):\n",
    "        print(f\"  {i+1:3}. {col}\")\n",
    "else:\n",
    "    raw_df = None\n",
    "    print(\"Questionnaire CSV not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first few rows\n",
    "if raw_df is not None:\n",
    "    print(\"First 5 rows:\")\n",
    "    display(raw_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "if raw_df is not None:\n",
    "    print(\"Data types:\")\n",
    "    print(raw_df.dtypes.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize QuestionnaireLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroalign_preprocessing.loaders import QuestionnaireLoader\n",
    "\n",
    "if QUESTIONNAIRE_CSV and Path(QUESTIONNAIRE_CSV).exists():\n",
    "    loader = QuestionnaireLoader(QUESTIONNAIRE_CSV)\n",
    "    print(f\"QuestionnaireLoader initialized\")\n",
    "    print(f\"  Path: {loader.questionnaire_path}\")\n",
    "else:\n",
    "    loader = None\n",
    "    print(\"Cannot initialize loader - CSV not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loader:\n",
    "    df = loader.load(\n",
    "        clean=True,\n",
    "        standardize_subject_codes=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Loaded and cleaned: {len(df)} rows\")\n",
    "    print(f\"\\nSubject Code format check (first 10):\")\n",
    "    print(df['Subject Code'].head(10).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Explore Feature Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show defined feature categories\n",
    "if loader:\n",
    "    print(\"Feature categories defined in loader:\")\n",
    "    print(f\"\\nDEMOGRAPHIC_FEATURES ({len(loader.DEMOGRAPHIC_FEATURES)}):\")\n",
    "    for f in loader.DEMOGRAPHIC_FEATURES:\n",
    "        exists = f in df.columns if df is not None else False\n",
    "        print(f\"  {'[x]' if exists else '[ ]'} {f}\")\n",
    "    \n",
    "    print(f\"\\nMENTAL_HEALTH_FEATURES ({len(loader.MENTAL_HEALTH_FEATURES)}):\")\n",
    "    for f in loader.MENTAL_HEALTH_FEATURES:\n",
    "        exists = f in df.columns if df is not None else False\n",
    "        print(f\"  {'[x]' if exists else '[ ]'} {f}\")\n",
    "    \n",
    "    print(f\"\\nPERSONALITY_FEATURES ({len(loader.PERSONALITY_FEATURES)}):\")\n",
    "    for f in loader.PERSONALITY_FEATURES:\n",
    "        exists = f in df.columns if df is not None else False\n",
    "        print(f\"  {'[x]' if exists else '[ ]'} {f}\")\n",
    "    \n",
    "    print(f\"\\nLIFESTYLE_FEATURES ({len(loader.LIFESTYLE_FEATURES)}):\")\n",
    "    for f in loader.LIFESTYLE_FEATURES:\n",
    "        exists = f in df.columns if df is not None else False\n",
    "        print(f\"  {'[x]' if exists else '[ ]'} {f}\")\n",
    "    \n",
    "    print(f\"\\nSOCIOECONOMIC_FEATURES ({len(loader.SOCIOECONOMIC_FEATURES)}):\")\n",
    "    for f in loader.SOCIOECONOMIC_FEATURES:\n",
    "        exists = f in df.columns if df is not None else False\n",
    "        print(f\"  {'[x]' if exists else '[ ]'} {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_feature_groups method\n",
    "if loader and loader.data is not None:\n",
    "    feature_groups = loader.get_feature_groups()\n",
    "    print(\"Available feature groups (from get_feature_groups):\")\n",
    "    for group, features in feature_groups.items():\n",
    "        print(f\"\\n{group} ({len(features)} features):\")\n",
    "        for f in features:\n",
    "            print(f\"    {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric vs categorical features\n",
    "if loader and loader.data is not None:\n",
    "    numeric_features = loader.get_numeric_features()\n",
    "    categorical_features = loader.get_categorical_features()\n",
    "    \n",
    "    print(f\"Numeric features ({len(numeric_features)}):\")\n",
    "    for f in numeric_features[:20]:\n",
    "        print(f\"  {f}\")\n",
    "    if len(numeric_features) > 20:\n",
    "        print(f\"  ... and {len(numeric_features) - 20} more\")\n",
    "    \n",
    "    print(f\"\\nCategorical features ({len(categorical_features)}):\")\n",
    "    for f in categorical_features[:20]:\n",
    "        print(f\"  {f}\")\n",
    "    if len(categorical_features) > 20:\n",
    "        print(f\"  ... and {len(categorical_features) - 20} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loader and loader.data is not None:\n",
    "    df = loader.data\n",
    "    \n",
    "    print(\"Data Quality Checks:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Missing values\n",
    "    print(\"\\n1. Missing values (top 20 columns):\")\n",
    "    missing = df.isnull().sum().sort_values(ascending=False)\n",
    "    missing_pct = (missing / len(df) * 100).round(2)\n",
    "    missing_df = pd.DataFrame({'missing': missing, 'pct': missing_pct})\n",
    "    display(missing_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate subject codes\n",
    "if loader and loader.data is not None:\n",
    "    df = loader.data\n",
    "    \n",
    "    print(\"\\n2. Duplicate subject codes:\")\n",
    "    dup_subjects = df['Subject Code'].value_counts()\n",
    "    dup_subjects = dup_subjects[dup_subjects > 1]\n",
    "    \n",
    "    if len(dup_subjects) > 0:\n",
    "        print(f\"  WARNING: {len(dup_subjects)} subjects have multiple entries:\")\n",
    "        display(dup_subjects.head(10))\n",
    "    else:\n",
    "        print(\"  OK: No duplicate subject codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check value ranges for key metrics\n",
    "if loader and loader.data is not None:\n",
    "    df = loader.data\n",
    "    \n",
    "    print(\"\\n3. Value ranges for mental health scales:\")\n",
    "    \n",
    "    # Expected ranges\n",
    "    expected_ranges = {\n",
    "        'PHQ9': (0, 27),       # Depression scale\n",
    "        'GAD7': (0, 21),       # Anxiety scale\n",
    "        'OASIS': (0, 20),      # Overall Anxiety\n",
    "        'PCL-5': (0, 80),      # PTSD checklist\n",
    "        'PSQI': (0, 21),       # Sleep quality\n",
    "        'Age': (18, 100),      # Reasonable age range\n",
    "    }\n",
    "    \n",
    "    for col, (exp_min, exp_max) in expected_ranges.items():\n",
    "        if col in df.columns:\n",
    "            actual_min = df[col].min()\n",
    "            actual_max = df[col].max()\n",
    "            n_out_of_range = ((df[col] < exp_min) | (df[col] > exp_max)).sum()\n",
    "            \n",
    "            status = \"OK\" if n_out_of_range == 0 else f\"WARNING ({n_out_of_range} out of range)\"\n",
    "            print(f\"  {col}: [{actual_min}, {actual_max}] expected [{exp_min}, {exp_max}] - {status}\")\n",
    "        else:\n",
    "            print(f\"  {col}: NOT FOUND in data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check categorical value distributions\n",
    "if loader and loader.data is not None:\n",
    "    df = loader.data\n",
    "    \n",
    "    print(\"\\n4. Categorical value distributions:\")\n",
    "    \n",
    "    for col in ['Gender', 'DominantHand', 'Marital Status', 'Education']:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n  {col}:\")\n",
    "            val_counts = df[col].value_counts(dropna=False)\n",
    "            for val, count in val_counts.items():\n",
    "                pct = count / len(df) * 100\n",
    "                print(f\"    {val}: {count} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics for Mental Health Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loader and loader.data is not None:\n",
    "    df = loader.data\n",
    "    \n",
    "    mental_health_cols = [c for c in loader.MENTAL_HEALTH_FEATURES if c in df.columns]\n",
    "    \n",
    "    if mental_health_cols:\n",
    "        print(\"Mental Health Scale Statistics:\")\n",
    "        display(df[mental_health_cols].describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for mental health scales\n",
    "if loader and loader.data is not None:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    df = loader.data\n",
    "    mental_health_cols = [c for c in loader.MENTAL_HEALTH_FEATURES if c in df.columns]\n",
    "    \n",
    "    if len(mental_health_cols) >= 2:\n",
    "        corr = df[mental_health_cols].corr()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        im = ax.imshow(corr, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        \n",
    "        ax.set_xticks(range(len(mental_health_cols)))\n",
    "        ax.set_yticks(range(len(mental_health_cols)))\n",
    "        ax.set_xticklabels(mental_health_cols, rotation=45, ha='right')\n",
    "        ax.set_yticklabels(mental_health_cols)\n",
    "        \n",
    "        plt.colorbar(im, ax=ax, label='Correlation')\n",
    "        plt.title('Mental Health Scale Correlations')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Participant Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary for a specific participant\n",
    "if loader and loader.data is not None:\n",
    "    df = loader.data\n",
    "    \n",
    "    # Pick first participant\n",
    "    test_subject = df['Subject Code'].iloc[0]\n",
    "    print(f\"Summary for participant: {test_subject}\")\n",
    "    \n",
    "    summary = loader.summarize_participant(test_subject)\n",
    "    \n",
    "    for category, data in summary.items():\n",
    "        print(f\"\\n{category.upper()}:\")\n",
    "        for key, value in data.items():\n",
    "            print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cohort Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cohort statistics for all participants\n",
    "if loader and loader.data is not None:\n",
    "    df = loader.data\n",
    "    \n",
    "    all_subjects = df['Subject Code'].tolist()\n",
    "    stats = loader.get_cohort_statistics(all_subjects)\n",
    "    \n",
    "    print(f\"Cohort statistics for {len(all_subjects)} participants:\")\n",
    "    \n",
    "    # Convert to DataFrame for nice display\n",
    "    stats_df = pd.DataFrame(stats).T\n",
    "    display(stats_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Merge with Sessions CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sessions CSV and merge\n",
    "if loader and loader.data is not None and SESSIONS_CSV and Path(SESSIONS_CSV).exists():\n",
    "    sessions_df = pd.read_csv(SESSIONS_CSV, dtype={'subject_code': str, 'session_id': str})\n",
    "    print(f\"Sessions CSV: {len(sessions_df)} rows\")\n",
    "    \n",
    "    # Merge\n",
    "    merged = loader.merge_with_sessions(\n",
    "        sessions_df,\n",
    "        on='Subject Code',\n",
    "        subject_col='subject_code'\n",
    "    )\n",
    "    \n",
    "    print(f\"Merged DataFrame: {len(merged)} rows\")\n",
    "    \n",
    "    # Check merge success\n",
    "    n_matched = merged['Subject Code'].notna().sum()\n",
    "    n_unmatched = merged['Subject Code'].isna().sum()\n",
    "    print(f\"\\nMatched: {n_matched} sessions\")\n",
    "    print(f\"Unmatched: {n_unmatched} sessions\")\n",
    "    \n",
    "    display(merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show unmatched sessions (if any)\n",
    "if 'merged' in dir() and merged is not None:\n",
    "    unmatched = merged[merged['Subject Code'].isna()]\n",
    "    if len(unmatched) > 0:\n",
    "        print(f\"Unmatched sessions ({len(unmatched)} total):\")\n",
    "        display(unmatched[['subject_code', 'session_id']].head(20))\n",
    "        \n",
    "        # Check if it's a subject code format issue\n",
    "        print(\"\\nSample session subject codes:\")\n",
    "        print(unmatched['subject_code'].head(5).tolist())\n",
    "        \n",
    "        print(\"\\nSample questionnaire subject codes:\")\n",
    "        print(loader.data['Subject Code'].head(5).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution\n",
    "if loader and loader.data is not None:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    df = loader.data\n",
    "    \n",
    "    if 'Age' in df.columns:\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        df['Age'].hist(bins=30, ax=ax)\n",
    "        ax.set_xlabel('Age')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_title('Age Distribution')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mental health score distributions\n",
    "if loader and loader.data is not None:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    df = loader.data\n",
    "    mh_cols = [c for c in ['PHQ9', 'GAD7', 'OASIS', 'PCL-5'] if c in df.columns]\n",
    "    \n",
    "    if mh_cols:\n",
    "        fig, axes = plt.subplots(1, len(mh_cols), figsize=(4*len(mh_cols), 4))\n",
    "        if len(mh_cols) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for ax, col in zip(axes, mh_cols):\n",
    "            df[col].hist(bins=20, ax=ax)\n",
    "            ax.set_xlabel(col)\n",
    "            ax.set_ylabel('Count')\n",
    "            ax.set_title(f'{col} Distribution')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Debug Specific Issues\n",
    "\n",
    "Use this section to debug specific issues you encounter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug a specific subject\n",
    "debug_subject = \"\"  # Fill in subject code\n",
    "\n",
    "if debug_subject and loader and loader.data is not None:\n",
    "    df = loader.data\n",
    "    \n",
    "    # Try to find the subject\n",
    "    exact_match = df[df['Subject Code'] == debug_subject]\n",
    "    \n",
    "    if len(exact_match) > 0:\n",
    "        print(f\"Found exact match for: {debug_subject}\")\n",
    "        display(exact_match.T)  # Transpose for easier reading\n",
    "    else:\n",
    "        # Try partial match\n",
    "        partial_matches = df[df['Subject Code'].str.contains(debug_subject, na=False)]\n",
    "        if len(partial_matches) > 0:\n",
    "            print(f\"No exact match, but found {len(partial_matches)} partial matches:\")\n",
    "            print(partial_matches['Subject Code'].tolist())\n",
    "        else:\n",
    "            print(f\"Subject {debug_subject} not found in questionnaire data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a specific column for issues\n",
    "debug_column = \"\"  # Fill in column name\n",
    "\n",
    "if debug_column and loader and loader.data is not None:\n",
    "    df = loader.data\n",
    "    \n",
    "    if debug_column in df.columns:\n",
    "        print(f\"Column: {debug_column}\")\n",
    "        print(f\"  Dtype: {df[debug_column].dtype}\")\n",
    "        print(f\"  Non-null: {df[debug_column].notna().sum()}\")\n",
    "        print(f\"  Null: {df[debug_column].isna().sum()}\")\n",
    "        \n",
    "        if df[debug_column].dtype in ['float64', 'int64']:\n",
    "            print(f\"  Min: {df[debug_column].min()}\")\n",
    "            print(f\"  Max: {df[debug_column].max()}\")\n",
    "            print(f\"  Mean: {df[debug_column].mean():.2f}\")\n",
    "        else:\n",
    "            print(f\"  Unique values: {df[debug_column].nunique()}\")\n",
    "            print(f\"  Value counts:\")\n",
    "            print(df[debug_column].value_counts().head(10).to_string())\n",
    "    else:\n",
    "        print(f\"Column {debug_column} not found\")\n",
    "        # Find similar column names\n",
    "        similar = [c for c in df.columns if debug_column.lower() in c.lower()]\n",
    "        if similar:\n",
    "            print(f\"Similar columns: {similar}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
